{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Implementación de un preprocesamiento de texto",
   "id": "c087ce4b75af17e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Importación de librerías\n",
    "Importamos las librerías necesarias para realizar el preprocesamiento de texto."
   ],
   "id": "6f597fb82bbbbaec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T01:16:51.500298Z",
     "start_time": "2024-05-03T01:16:50.993767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Carga el modelo de lenguaje.\n",
    "# En caso de no tenerlo instalado, ejecutar el siguiente comando:\n",
    "# python -m spacy download en_core_web_sm\n",
    "# Para español: es_core_news_sm\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "id": "cd727af7570d2047",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Normalización de texto\n",
    "La normalización de texto es un paso importante en el preprocesamiento de texto. Consiste en realizar una serie de transformaciones para que el texto sea más fácil de procesar. Lo que hicimos en este caso fue:\n",
    "1. **Tokenizar el texto**: separar el texto en palabras.\n",
    "2. **Limpiar el texto**: eliminar las URLs, menciones, hashtags, signos de puntuación, espacios, dígitos y palabras con menos de 2 caracteres.\n",
    "3. **Lemmatizar el texto**: convertir las palabras a su forma base."
   ],
   "id": "2b087228dfcf53f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T02:36:25.580298Z",
     "start_time": "2024-05-03T02:36:25.574431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize(text) -> str:\n",
    "    URL_PATTERN = re.compile(\n",
    "        r\"\"\"(?:https?:\\/\\/)?(?:www\\.)?(?:[a-zA-Z0-9-]+\\.[a-zA-Z]{2,6})(?:[-a-zA-Z0-9@:%_\\+.~#?&\\/\\/=]*)\"\"\")\n",
    "    MENTION_PATTERN = re.compile(r\"@\\S+\")\n",
    "    HASHTAG_PATTERN = re.compile(r\"#\\S+\")\n",
    "    RT_PATTERN = re.compile(r\"RT\")\n",
    "    LETTERS_PATTERN = re.compile(r\"[^a-zA-Z]\")\n",
    "\n",
    "    # Tokenizar el texto\n",
    "    tokens = nlp(text)\n",
    "\n",
    "    # Limpiar el texto\n",
    "    tokens = [token for token in tokens\n",
    "              if not re.match(URL_PATTERN, token.text)\n",
    "              and not re.match(MENTION_PATTERN, token.text)\n",
    "              and not re.match(HASHTAG_PATTERN, token.text)\n",
    "              and not re.match(RT_PATTERN, token.text)\n",
    "              and not re.match(LETTERS_PATTERN, token.text)\n",
    "              and not token.is_stop\n",
    "              and not token.is_punct\n",
    "              and not token.is_space\n",
    "              and not token.is_digit\n",
    "              and len(token.text) > 2]\n",
    "\n",
    "    # Lemmatizar el texto\n",
    "    text = \" \".join([unidecode(token.lemma_.strip().lower()) for token in tokens])\n",
    "\n",
    "    return text"
   ],
   "id": "46b37b74d06c56a3",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T02:36:26.113023Z",
     "start_time": "2024-05-03T02:36:26.079842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentences = [\"I'm learning Python and I'm enjoying it. :) >.<\",\n",
    "             \"I have a website at https://www.example.com with discounts.\",\n",
    "             \"What do you think about the new product from @company? #opinions\",\n",
    "             \"RT @user: Thanks for the retweet. Great article! 😃\",\n",
    "             \"10 ways to improve your mental health. #health #wellness 🧘‍♂️\"]\n",
    "for sentence in sentences:\n",
    "    print(\"\\nTexto original:\", sentence)\n",
    "    print(\"Texto normalizado:\", normalize(sentence))"
   ],
   "id": "f6f471c8a48ecb00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto original: I'm learning Python and I'm enjoying it. :) >.<\n",
      "Texto normalizado: learn python enjoy\n",
      "\n",
      "Texto original: I have a website at https://www.example.com with discounts.\n",
      "Texto normalizado: website discount\n",
      "\n",
      "Texto original: What do you think about the new product from @company? #opinions\n",
      "Texto normalizado: think new product opinion\n",
      "\n",
      "Texto original: RT @user: Thanks for the retweet. Great article! 😃\n",
      "Texto normalizado: thank retweet great article\n",
      "\n",
      "Texto original: 10 ways to improve your mental health. #health #wellness 🧘‍♂️\n",
      "Texto normalizado: way improve mental health health wellness\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocesamiento de un dataset",
   "id": "2efcd2bd4c08eea0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-03T02:44:54.494287Z",
     "start_time": "2024-05-03T02:36:33.236519Z"
    }
   },
   "source": [
    "# Cargo el dataset\n",
    "df = pd.read_csv('../data/cyberbullying.csv')\n",
    "# Renombra las columnas\n",
    "df.columns = ['text', 'label']\n",
    "\n",
    "# Normalizar el texto\n",
    "df['text_preprocessed'] = df['text'].progress_apply(normalize)\n",
    "\n",
    "# Eliminar las filas con texto preprocessado vacío\n",
    "df = df[df['text_preprocessed'] != '']\n",
    "\n",
    "# Guardar el dataset preprocesado\n",
    "df.to_csv('../data/cyberbullying_preprocessed.csv', index=False)\n",
    "\n",
    "# Display the first rows\n",
    "print(df.head())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81417/81417 [08:20<00:00, 162.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  \\\n",
      "0  In other words #katandandre, your food was cra...      0   \n",
      "1  Why is #aussietv so white? #MKR #theblock #ImA...      0   \n",
      "2  @XochitlSuckkks a classy whore? Or more red ve...      0   \n",
      "3  @Jason_Gio meh. :P  thanks for the heads up, b...      0   \n",
      "4  @RudhoeEnglish This is an ISIS account pretend...      0   \n",
      "\n",
      "                                   text_preprocessed  \n",
      "0             word katandandre food crapilicious mkr  \n",
      "1  aussietv white mkr theblock imacelebrityau tod...  \n",
      "2                    classy whore red velvet cupcake  \n",
      "3        meh thank head concerned angry dude twitter  \n",
      "4  isis account pretend kurdish account like isla...  \n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T02:47:03.973082Z",
     "start_time": "2024-05-03T02:47:03.677284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../data/cyberbullying_preprocessed.csv')\n",
    "df.head()"
   ],
   "id": "db5084047ce2bc9a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text  label  \\\n",
       "0  In other words #katandandre, your food was cra...      0   \n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...      0   \n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...      0   \n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...      0   \n",
       "4  @RudhoeEnglish This is an ISIS account pretend...      0   \n",
       "\n",
       "                                   text_preprocessed  \n",
       "0             word katandandre food crapilicious mkr  \n",
       "1  aussietv white mkr theblock imacelebrityau tod...  \n",
       "2                    classy whore red velvet cupcake  \n",
       "3        meh thank head concerned angry dude twitter  \n",
       "4  isis account pretend kurdish account like isla...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>0</td>\n",
       "      <td>word katandandre food crapilicious mkr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>0</td>\n",
       "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>classy whore red velvet cupcake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>0</td>\n",
       "      <td>meh thank head concerned angry dude twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>0</td>\n",
       "      <td>isis account pretend kurdish account like isla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "79ce0682d55c4330"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
