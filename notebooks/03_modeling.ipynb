{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:40:57.342388Z",
     "start_time": "2024-05-03T03:40:57.325399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "b8de7fb4d02d44ad",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-03T03:11:41.101693Z",
     "start_time": "2024-05-03T03:11:40.695051Z"
    }
   },
   "source": [
    "df = pd.read_csv('../data/cyberbullying_preprocessed.csv')\n",
    "data = [tuple(x) for x in df.values]\n",
    "print('Número de datos cargados: {num}'.format(num=len(data)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de datos cargados: 80984\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:11:41.150562Z",
     "start_time": "2024-05-03T03:11:41.103702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Divido los datos en dos listas \n",
    "#     X: los mensajes de texto\n",
    "#     y: las etiquetas\n",
    "\n",
    "X = [doc[2] for doc in data]\n",
    "y = [doc[1] for doc in data]\n",
    "\n",
    "print(pd.DataFrame({'X': X, 'y': y}))"
   ],
   "id": "4ad0f36c6a52e5d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       X  y\n",
      "0                 word katandandre food crapilicious mkr  0\n",
      "1      aussietv white mkr theblock imacelebrityau tod...  0\n",
      "2                        classy whore red velvet cupcake  0\n",
      "3            meh thank head concerned angry dude twitter  0\n",
      "4      isis account pretend kurdish account like isla...  0\n",
      "...                                                  ... ..\n",
      "80979                                     happy birthday  0\n",
      "80980  agree awful make sense regardless mistake dese...  0\n",
      "80981  call yesterday guidance counselor office think...  0\n",
      "80982                                              thank  0\n",
      "80983                 think find good group help refocus  0\n",
      "\n",
      "[80984 rows x 2 columns]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:11:41.762147Z",
     "start_time": "2024-05-03T03:11:41.152568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cargamos el vector TF-IDF y ajustamos los datos\n",
    "tfidf_vectorizer = joblib.load('../models/tfidf_vectorizer.pkl')\n",
    "X = tfidf_vectorizer.transform(X)"
   ],
   "id": "e54725fc9af06c44",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dividimos los datos en dos conjuntos: entrenamiento y test\n",
    "- El conjunto de entrenamiento se utiliza para ajustar el modelo\n",
    "- El conjunto de test se utiliza para evaluar el modelo\n",
    "- La proporción de los datos que se utilizan para el test es del 20%\n",
    "- La semilla aleatoria se fija en 0 para que los resultados sean reproducibles\n",
    "- Se imprime el número de mensajes que se utilizarán para el entrenamiento y el test"
   ],
   "id": "a8dce84bd2c1f3c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:11:41.785132Z",
     "start_time": "2024-05-03T03:11:41.763153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print('Número de Mensajes para el entrenamiento: {num}'.format(num=X_train.shape[0]))\n",
    "print('Número de Mensajes para el test: {num}'.format(num=X_test.shape[0]))"
   ],
   "id": "3ef97e0feefa66e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de Mensajes para el entrenamiento: 64787\n",
      "Número de Mensajes para el test: 16197\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Clasificadores\n",
    "Hacemos uso de los siguientes clasificadores:\n",
    "- Naive Bayes.\n",
    "    - Multinomial Naive Bayes\n",
    "    - Bernoulli Naive Bayes\n",
    "- Regresión Logística.\n",
    "- Máquinas de Soporte Vectorial (SVM).\n",
    "    - Lineal\n",
    "    - Polinómico\n",
    "    - Radial\n",
    "    - Sigmoide\n",
    "- Random Forest.\n",
    "    - Random Forest con profundidad de 20\n",
    "    - Random Forest con profundidad de 50\n",
    "\n",
    "### Naive Bayes\n",
    "Es un clasificador probabilístico que se basa en el teorema de Bayes. Se utilizan diferentes tipos de Naive Bayes:\n",
    "- Multinomial Naive Bayes: Se utiliza para datos discretos.\n",
    "- Bernoulli Naive Bayes: Se utiliza para datos binarios.\n",
    "\n",
    "### Regresión Logística\n",
    "Es un clasificador lineal que se utiliza para problemas de clasificación binaria y multiclase.\n",
    "\n",
    "### Máquinas de Soporte Vectorial (SVM)\n",
    "Es un clasificador lineal que se utiliza para problemas de clasificación binaria y multiclase.\n",
    "- Se utilizan diferentes kernels: lineal, polinómico, radial y sigmoide.\n",
    "\n",
    "### Random Forest\n",
    "Es un clasificador que se basa en la combinación de árboles de decisión. Se utilizan diferentes profundidades para los árboles de decisión."
   ],
   "id": "4cfa170cc782843f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:11:41.889647Z",
     "start_time": "2024-05-03T03:11:41.785132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importamos los clasificadores\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "id": "ce69b27baf6b7509",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:11:41.897538Z",
     "start_time": "2024-05-03T03:11:41.890653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inicializamos los clasificadores\n",
    "multinomial_nb_classifier = MultinomialNB()\n",
    "bernoulli_nb_classifier = BernoulliNB()\n",
    "\n",
    "logistic_regression_classifier = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "\n",
    "linear_svm_classifier = SVC(kernel='linear')\n",
    "poly_svm_classifier = SVC(kernel='poly')\n",
    "rbf_svm_classifier = SVC(kernel='rbf')\n",
    "sigmoid_svm_classifier = SVC(kernel='sigmoid')\n",
    "\n",
    "random_forest_depth_20_classifier = RandomForestClassifier(n_estimators=500, bootstrap=True, criterion='gini',\n",
    "                                                           max_depth=20, random_state=0)\n",
    "random_forest_depth_50_classifier = RandomForestClassifier(n_estimators=500, bootstrap=True, criterion='gini',\n",
    "                                                           max_depth=50, random_state=0)"
   ],
   "id": "52f06f9e13b64fb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:51:10.588337Z",
     "start_time": "2024-05-03T03:51:10.584989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creamos un diccionario con los clasificadores\n",
    "classifiers = {'Multinomial NB': multinomial_nb_classifier,\n",
    "               'Bernoulli NB': bernoulli_nb_classifier,\n",
    "               'Logistic Regression': logistic_regression_classifier,\n",
    "               'Linear SVM': linear_svm_classifier,\n",
    "               'Polynomial SVM': poly_svm_classifier,\n",
    "               'RBF Kernel SVM': rbf_svm_classifier,\n",
    "               'Sigmoid Kernel SVM': sigmoid_svm_classifier,\n",
    "               'Random Forest Depth 20': random_forest_depth_20_classifier,\n",
    "               'Random Forest Depth 50': random_forest_depth_50_classifier}"
   ],
   "id": "3479d9361739267d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:40:51.801236Z",
     "start_time": "2024-05-03T03:11:41.899546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Entrenamos los clasificadores\n",
    "print(f\"Entramiento de los clasificadores\\n{'=' * 30}\")\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    print(f\"Entrenando {classifier_name}...\")\n",
    "    classifier.fit(X_train, y_train)"
   ],
   "id": "effdf6d2611e26b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entramiento de los clasificadores\n",
      "==============================\n",
      "Entrenando Multinomial NB...\n",
      "Entrenando Bernoulli NB...\n",
      "Entrenando Logistic Regression...\n",
      "Entrenando Linear SVM...\n",
      "Entrenando Polynomial SVM...\n",
      "Entrenando RBF Kernel SVM...\n",
      "Entrenando Sigmoid Kernel SVM...\n",
      "Entrenando Random Forest Depth 20...\n",
      "Entrenando Random Forest Depth 50...\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:42:20.196417Z",
     "start_time": "2024-05-03T03:42:19.750588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Guardamos los clasificadores entrenados\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    print(f\"Guardando {classifier_name}...\")\n",
    "    joblib.dump(classifier, f'../models/{classifier_name.lower().replace(\" \", \"_\")}.pkl')"
   ],
   "id": "2596ace64302a00e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando Multinomial NB...\n",
      "Guardando Bernoulli NB...\n",
      "Guardando Logistic Regression...\n",
      "Guardando Linear SVM...\n",
      "Guardando Polynomial SVM...\n",
      "Guardando RBF Kernel SVM...\n",
      "Guardando Sigmoid Kernel SVM...\n",
      "Guardando Random Forest Depth 20...\n",
      "Guardando Random Forest Depth 50...\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:51:31.983518Z",
     "start_time": "2024-05-03T03:51:31.330726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cargamos los clasificadores entrenados\n",
    "for classifier_name in classifiers.keys():\n",
    "    print(f\"Cargando {classifier_name}...\")\n",
    "    classifiers[classifier_name] = joblib.load(f'../models/{classifier_name.lower().replace(\" \", \"_\")}.pkl')"
   ],
   "id": "27ea42aa6d4d7801",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando Multinomial NB...\n",
      "Cargando Bernoulli NB...\n",
      "Cargando Logistic Regression...\n",
      "Cargando Linear SVM...\n",
      "Cargando Polynomial SVM...\n",
      "Cargando RBF Kernel SVM...\n",
      "Cargando Sigmoid Kernel SVM...\n",
      "Cargando Random Forest Depth 20...\n",
      "Cargando Random Forest Depth 50...\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:55:14.194365Z",
     "start_time": "2024-05-03T03:55:14.188679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluamos los atributos (accuracy, precision, recall, f1) de los clasificadores, tanto los datos de entrenamiento y prueba.\n",
    "# accuracy: mide la fracción de predicciones correctas\n",
    "# precision: mide la fracción de predicciones correctas de la clase positiva\n",
    "# recall: mide la fracción de instancias positivas que fueron correctamente clasificadas\n",
    "# f1: media armónica de precision y recall\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def evaluation_metrics(model, name, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "    test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    return [name, train_accuracy, test_accuracy, train_precision, test_precision, train_recall, test_recall, train_f1,\n",
    "            test_f1]"
   ],
   "id": "c2443e372e402a09",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T04:09:06.264649Z",
     "start_time": "2024-05-03T03:55:14.647399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculamos as metricas de evaluacion para cada clasificador\n",
    "evaluation_results = []\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    # print(f\"Calculando métricas de evaluación para {classifier_name}...\")\n",
    "    evaluation_results.append(evaluation_metrics(classifier, classifier_name, X_train, y_train, X_test, y_test))\n",
    "\n",
    "df_evaluation_results = pd.DataFrame.from_dict(evaluation_results)\n",
    "df_evaluation_results.columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Train Precision', 'Test Precision',\n",
    "                                  'Train Recall', 'Test Recall', 'Train F1', 'Test F1']\n",
    "df_evaluation_results"
   ],
   "id": "3cde181f3b107b2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando métricas de evaluación para Multinomial NB...\n",
      "Calculando métricas de evaluación para Bernoulli NB...\n",
      "Calculando métricas de evaluación para Logistic Regression...\n",
      "Calculando métricas de evaluación para Linear SVM...\n",
      "Calculando métricas de evaluación para Polynomial SVM...\n",
      "Calculando métricas de evaluación para RBF Kernel SVM...\n",
      "Calculando métricas de evaluación para Sigmoid Kernel SVM...\n",
      "Calculando métricas de evaluación para Random Forest Depth 20...\n",
      "Calculando métricas de evaluación para Random Forest Depth 50...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                    Model  Train Accuracy  Test Accuracy  Train Precision  \\\n",
       "0          Multinomial NB        0.745829       0.743903         0.742345   \n",
       "1            Bernoulli NB        0.772068       0.770266         0.801503   \n",
       "2     Logistic Regression        0.787164       0.777737         0.796736   \n",
       "3              Linear SVM        0.787118       0.781256         0.811575   \n",
       "4          Polynomial SVM        0.900119       0.781750         0.899891   \n",
       "5          RBF Kernel SVM        0.875052       0.790579         0.881195   \n",
       "6      Sigmoid Kernel SVM        0.726674       0.747855         0.735801   \n",
       "7  Random Forest Depth 20        0.783166       0.768846         0.801845   \n",
       "8  Random Forest Depth 50        0.822711       0.784713         0.862328   \n",
       "\n",
       "   Test Precision  Train Recall  Test Recall  Train F1   Test F1  \n",
       "0        0.740215      0.745829     0.743903  0.742142  0.739885  \n",
       "1        0.799174      0.772068     0.770266  0.774798  0.773101  \n",
       "2        0.787945      0.787164     0.777737  0.789233  0.779977  \n",
       "3        0.807505      0.787118     0.781256  0.789721  0.783986  \n",
       "4        0.781923      0.900119     0.781750  0.899966  0.781834  \n",
       "5        0.801505      0.875052     0.790579  0.876111  0.792764  \n",
       "6        0.757207      0.726674     0.747855  0.729173  0.750251  \n",
       "7        0.785983      0.783166     0.768846  0.785766  0.771619  \n",
       "8        0.818175      0.822711     0.784713  0.824619  0.787278  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial NB</td>\n",
       "      <td>0.745829</td>\n",
       "      <td>0.743903</td>\n",
       "      <td>0.742345</td>\n",
       "      <td>0.740215</td>\n",
       "      <td>0.745829</td>\n",
       "      <td>0.743903</td>\n",
       "      <td>0.742142</td>\n",
       "      <td>0.739885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bernoulli NB</td>\n",
       "      <td>0.772068</td>\n",
       "      <td>0.770266</td>\n",
       "      <td>0.801503</td>\n",
       "      <td>0.799174</td>\n",
       "      <td>0.772068</td>\n",
       "      <td>0.770266</td>\n",
       "      <td>0.774798</td>\n",
       "      <td>0.773101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.787164</td>\n",
       "      <td>0.777737</td>\n",
       "      <td>0.796736</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.787164</td>\n",
       "      <td>0.777737</td>\n",
       "      <td>0.789233</td>\n",
       "      <td>0.779977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.787118</td>\n",
       "      <td>0.781256</td>\n",
       "      <td>0.811575</td>\n",
       "      <td>0.807505</td>\n",
       "      <td>0.787118</td>\n",
       "      <td>0.781256</td>\n",
       "      <td>0.789721</td>\n",
       "      <td>0.783986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>0.900119</td>\n",
       "      <td>0.781750</td>\n",
       "      <td>0.899891</td>\n",
       "      <td>0.781923</td>\n",
       "      <td>0.900119</td>\n",
       "      <td>0.781750</td>\n",
       "      <td>0.899966</td>\n",
       "      <td>0.781834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RBF Kernel SVM</td>\n",
       "      <td>0.875052</td>\n",
       "      <td>0.790579</td>\n",
       "      <td>0.881195</td>\n",
       "      <td>0.801505</td>\n",
       "      <td>0.875052</td>\n",
       "      <td>0.790579</td>\n",
       "      <td>0.876111</td>\n",
       "      <td>0.792764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sigmoid Kernel SVM</td>\n",
       "      <td>0.726674</td>\n",
       "      <td>0.747855</td>\n",
       "      <td>0.735801</td>\n",
       "      <td>0.757207</td>\n",
       "      <td>0.726674</td>\n",
       "      <td>0.747855</td>\n",
       "      <td>0.729173</td>\n",
       "      <td>0.750251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest Depth 20</td>\n",
       "      <td>0.783166</td>\n",
       "      <td>0.768846</td>\n",
       "      <td>0.801845</td>\n",
       "      <td>0.785983</td>\n",
       "      <td>0.783166</td>\n",
       "      <td>0.768846</td>\n",
       "      <td>0.785766</td>\n",
       "      <td>0.771619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest Depth 50</td>\n",
       "      <td>0.822711</td>\n",
       "      <td>0.784713</td>\n",
       "      <td>0.862328</td>\n",
       "      <td>0.818175</td>\n",
       "      <td>0.822711</td>\n",
       "      <td>0.784713</td>\n",
       "      <td>0.824619</td>\n",
       "      <td>0.787278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ce744e8914a85625"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
